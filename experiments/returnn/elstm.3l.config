#!crnn/rnn.py
# kate: syntax python;
# base: chime speed base setup

# data
task = "train"
train = "data/train.0001"
device = "gpu0"
multiprocessing = True
update_on_device = True
learning_rate_file = "newbob.data"
#cache_size = "2G"  # why ... #for dataset

# network
num_inputs = 45
num_outputs = 1501
batching = "default"  # for full seq training, you might also want to try "sorted"
batch_size = 20250
max_seqs = 81
# chunking = "50:25"  #  - no chunking here
window = 1
network = {
"lstm0_fw" : { "class" : "rec", "unit": "lstme", "n_out" : 512, "direction" : 1 },
"lstm0_bw" : { "class" : "rec", "unit": "lstme", "n_out" : 512, "direction" : -1 },

"lstm1_fw" : { "class" : "rec", "unit": "lstme", "n_out" : 512, "direction" : 1,  "from" : ["lstm0_fw", "lstm0_bw"] },
"lstm1_bw" : { "class" : "rec", "unit": "lstme", "n_out" : 512, "direction" : -1, "from" : ["lstm0_fw", "lstm0_bw"] },

"lstm2_fw" : { "class" : "rec", "unit": "lstme", "n_out" : 512, "direction" : 1,  "from" : ["lstm1_fw", "lstm1_bw"] },
"lstm2_bw" : { "class" : "rec", "unit": "lstme", "n_out" : 512, "direction" : -1, "from" : ["lstm1_fw", "lstm1_bw"] },

"output" :   { "class" : "softmax",  "loss" : "ce", "from" : ["lstm2_fw", "lstm2_bw"] }
}

# trainer
truncation = -1
num_epochs = 50
gradient_clip = 10
learning_rate = 0.001
model = "model/network"

# log
log = "log/crnn.train.log"
log_verbosity = 4  # 5 will output for every batch

